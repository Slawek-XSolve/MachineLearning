{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import bibliotek i podstawowa konfiguracja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "import re\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import xgbfir\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import brewer2mpl\n",
    "\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "from functools import partial\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(2018)\n",
    "\n",
    "pd.set_option('max_rows', 200)\n",
    "pd.set_option('max_columns', 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapa miast i województw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voivodeships = pd.read_csv('./default/provinces.csv')\n",
    "cities = pd.read_csv('./default/places.csv')\n",
    "cities = pd.merge(cities, voivodeships, on='province_id')\n",
    "cities['city_name'] = cities['city_name'].map(lambda x: x.lower())\n",
    "\n",
    "city_to_voivodeship_map = dict(zip(cities['city_name'], cities['province_name']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_train = pd.read_hdf('./input/train.car_price.h5')\n",
    "train = original_train.copy()\n",
    "\n",
    "original_test = pd.read_hdf('./input/test.car_price.h5')\n",
    "test = original_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![](../images/dummy_benchmark.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funkcje pomocnicze do serializacji i normalizacji danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_filter(val):\n",
    "    return re.sub('[^0-9]','', val)\n",
    "\n",
    "def float_filter(val):\n",
    "    return re.sub('[^0-9\\,\\.]','', val).replace(',', '.')\n",
    "\n",
    "def str_filter(val):\n",
    "    return val.lower().strip()\n",
    "\n",
    "def extract_city(address):\n",
    "    if address == None:\n",
    "        return None\n",
    "    \n",
    "    city = address.split(',')[0]\n",
    "    \n",
    "    if ' - ' in city: \n",
    "        city = city.split(' - ')[-1][7:]\n",
    "    \n",
    "    city = city.lower().strip()\n",
    "    \n",
    "    return city\n",
    "\n",
    "def norm_date(value):\n",
    "    if value is None: return value\n",
    "    \n",
    "    months_to_digit = {\n",
    "        'styczeń': 1,\n",
    "        'luty': 2,\n",
    "        'marzec': 3,\n",
    "        'kwiecień': 4,\n",
    "        'maj': 5,\n",
    "        'czerwiec': 6,\n",
    "        'lipiec': 7,\n",
    "        'sierpień': 8,\n",
    "        'wrzesień': 9,\n",
    "        'październik': 10,\n",
    "        'listopad': 11,\n",
    "        'grudzień': 12,\n",
    "        'january': 1,\n",
    "        'february': 2,\n",
    "        'march': 3,\n",
    "        'april': 4,\n",
    "        'may': 5,\n",
    "        'june': 6,\n",
    "        'july': 7,\n",
    "        'august': 8,\n",
    "        'september': 9,\n",
    "        'october': 10,\n",
    "        'november': 11,\n",
    "        'december': 12\n",
    "    }\n",
    "    values = value.split(' ')\n",
    "\n",
    "    day   = values[0] if len(values) == 3 else None\n",
    "    month = values[-2].lower()\n",
    "    year  = values[-1]\n",
    "\n",
    "    month = months_to_digit[month]\n",
    "\n",
    "    if day is None:\n",
    "        return '{0}/{1}'.format( month, year)\n",
    "\n",
    "    return '{0}/{1}/{2}'.format( day, month, year)\n",
    "\n",
    "def merge_labels(df, label0, label1, label, transform=(lambda x: x), unknown_value=None, del_feat=True):\n",
    "    df[label] = [transform(a) if a != None else transform(b) if b != None else unknown_value for a, b in zip(df[label0], df[label1])]\n",
    "\n",
    "    if del_feat:\n",
    "        del df[label0]\n",
    "        del df[label1]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funkcje pomocnicze do kategoryzacji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_feature(df, feat, feat_cat, indexers, del_feat=True, average_func=np.median, unknown_cat_name='unknown', unknown_cat_val=-1):\n",
    "    if feat in indexers:\n",
    "        return categorize_feature_for_test(df, feat, feat_cat, indexers[feat], del_feat=del_feat, unknown_cat_name=unknown_cat_name, unknown_cat_val=unknown_cat_val)\n",
    "    \n",
    "    categories_map = categorize_feature_for_train(df, feat, feat_cat, indexers, del_feat=del_feat, average_func=average_func, unknown_cat_name=unknown_cat_name)\n",
    "    \n",
    "def categorize_feature_for_test(df, feat, feat_cat, categories_map, del_feat=True, unknown_cat_name='unknown', unknown_cat_val=-1):\n",
    "    df[feat_cat] = [categories_map[x] if x in categories_map \n",
    "                    else categories_map[unknown_cat_name] if unknown_cat_name in categories_map \n",
    "                    else unknown_cat_val for x in df[feat]]\n",
    "    \n",
    "    if del_feat:\n",
    "        del df[feat]\n",
    "    \n",
    "def categorize_feature_for_train(df, feat, feat_cat, indexers, del_feat=True, average_func=np.median, unknown_cat_name='unknown'):\n",
    "    df.loc[df[feat].isnull(), feat] = unknown_cat_name\n",
    "\n",
    "    unique_categories = set(df[feat])\n",
    "    avg_price_value = average_func(df['price_value'])\n",
    "\n",
    "    categories_info = {}\n",
    "\n",
    "    for cat in unique_categories:\n",
    "        rows = df[df[feat] == cat]\n",
    "        if cat != unknown_cat_name:\n",
    "            categories_info[cat] = (cat, len(rows), average_func(rows['price_value']))\n",
    "        else:\n",
    "            categories_info[cat] = (cat, len(rows), avg_price_value)\n",
    "\n",
    "    categories_info = sorted(list(categories_info.values()), key=lambda tup: tup[2])\n",
    "    categories_map = {}\n",
    "\n",
    "    for i, (cat, l, avg) in enumerate(categories_info):\n",
    "        categories_map[cat] = i\n",
    "\n",
    "    for cat, ind in categories_map.items():\n",
    "        df.loc[df[feat] == cat, feat_cat] = ind\n",
    "\n",
    "    indexers[feat] = categories_map\n",
    "    \n",
    "    if del_feat:\n",
    "        del df[feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_train['invoice_vat'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funkcja do przygotowania danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df, train_indexers=None):\n",
    "    indexers = train_indexers if train_indexers != None else {}\n",
    "\n",
    "    feats_useless = ['price_details', 'param_vin', 'breadcrumb']\n",
    "    feats_redundant = []\n",
    "    \n",
    "    bool_transform = lambda x: x == 'Tak'\n",
    "    \n",
    "    # param_bezwypadkowy {'Tak' (66723), None (39771)}, param_no-accident {'Tak' (48), None (106446)} -> accident_free\n",
    "    merge_labels(df, 'param_bezwypadkowy', 'param_no-accident', 'accident_free', transform=bool_transform, unknown_value=False)\n",
    "\n",
    "    # param_uszkodzony {'Tak' (4250), None (102244)}, param_damaged {'Tak' (4), None (106490)} -> damaged\n",
    "    merge_labels(df, 'param_uszkodzony', 'param_damaged', 'damaged', transform=bool_transform, unknown_value=False)\n",
    "    \n",
    "    # param_faktura-vat {'Tak' (26389), None (80105)} -> invoice_vat\n",
    "    df['invoice_vat'] = df['param_faktura-vat'].map(bool_transform)\n",
    "    feats_redundant.append('param_faktura-vat')\n",
    "\n",
    "    # param_perłowy {'Tak' (11493), None (95001)}, param_pearl {'Tak' (3), None (106491)} -> pearl_car_paint\n",
    "    merge_labels(df, 'param_perłowy', 'param_pearl', 'pearl_car_paint', transform=bool_transform, unknown_value=False)\n",
    "\n",
    "    # param_homologacja-ciężarowa {'Tak' (764), None (105730)} -> truck\n",
    "    df['truck'] = df['param_homologacja-ciężarowa'].map(bool_transform)\n",
    "    feats_redundant.append('param_homologacja-ciężarowa')\n",
    "\n",
    "    # param_service-record {'Tak' (40), None (106454)}, param_serwisowany-w-aso {'Tak' (52314), None (54180)} -> service_record\n",
    "    merge_labels(df, 'param_service-record', 'param_serwisowany-w-aso', 'service_record', transform=bool_transform, unknown_value=False)\n",
    "\n",
    "    # param_metallic {'Tak' (40), None (106454)}, param_metalik {'Tak' (72520), 'metallic' (20) None (33954)} -> metallic_car_paint\n",
    "    merge_labels(df, 'param_metallic', 'param_metalik', 'metallic_car_paint', transform=lambda x: x == 'Tak' or x == 'metallic', unknown_value=False)\n",
    "\n",
    "    # param_leasing-concession {'Tak' (11), None (106483)} -> leasing_concession\n",
    "#     df['leasing_concession'].map(bool_transform)\n",
    "    feats_redundant.append('param_leasing-concession')\n",
    "\n",
    "    # param_financing-option {'Tak' (29), None (106465)}, param_możliwość-finansowania {'Tak' (35540), None (70954)} -> financing_option\n",
    "    merge_labels(df, 'param_financing-option', 'param_możliwość-finansowania', 'financing_option', transform=bool_transform, unknown_value=False)\n",
    "\n",
    "    # param_original-owner {'Tak' (39), None (106455)} -> original_owner\n",
    "    df['original_owner'] = df['param_original-owner'].map(bool_transform)\n",
    "    feats_redundant.append('param_original-owner')\n",
    "\n",
    "    # param_vat-marża {'Tak' (39), None (106455)} -> vat_margin\n",
    "    df['vat_margin'] = df['param_vat-marża'].map(bool_transform)\n",
    "    feats_redundant.append('param_vat-marża')\n",
    "\n",
    "    # param_kategoria {'Osobowe' (106385), None (109)} -> passenger_car\n",
    "    df['passenger_car'] = df['param_kategoria'] == 'Osobowe'\n",
    "    feats_redundant.append('param_kategoria')\n",
    "\n",
    "    # param_leasing {'Tak' (11454), None (95040)} -> leasing\n",
    "    df['leasing'] = df['param_leasing'].map(bool_transform)\n",
    "    feats_redundant.append('param_leasing')\n",
    "\n",
    "    # param_zarejestrowany-jako-zabytek {'Tak' (80), None (106414)} -> antique\n",
    "    df['antique'] = df['param_zarejestrowany-jako-zabytek'].map(bool_transform)\n",
    "    feats_redundant.append('param_zarejestrowany-jako-zabytek')\n",
    "\n",
    "    # param_pierwszy-właściciel {'Tak' (47115), None (59379)} -> first_owner\n",
    "    df['first_owner'] = df['param_pierwszy-właściciel'].map(bool_transform)\n",
    "    feats_redundant.append('param_pierwszy-właściciel')\n",
    "\n",
    "    # param_vat-discount {'Tak' (21), None (106473)} -> vat_discount\n",
    "    df['vat_discount'] = df['param_vat-discount'].map(bool_transform)\n",
    "    feats_redundant.append('param_vat-discount')\n",
    "\n",
    "    # param_particle-filter {'Tak' (7), None (106487)}, param_filtr-cząstek-stałych {'Tak' (6274), None (100220)} -> particle_filter\n",
    "    merge_labels(df, 'param_particle-filter', 'param_filtr-cząstek-stałych', 'particle_filter', transform=bool_transform, unknown_value=False)\n",
    "\n",
    "    # param_zarejestrowany-w-polsce {'Tak' (49132), None (57362)}, param_registered-in-poland {'Tak' (39), None (106455)} -> registered_in_poland\n",
    "    merge_labels(df, 'param_zarejestrowany-w-polsce', 'param_registered-in-poland', 'particle_filter', transform=bool_transform, unknown_value=False)\n",
    "\n",
    "    # param_kierownica-po-prawej-(anglik) {'Tak' (793), None (105701)} -> right_hand_steering_wheel\n",
    "    df['right_hand_steering_wheel'] = df['param_kierownica-po-prawej-(anglik)'].map(bool_transform)\n",
    "    feats_redundant.append('param_kierownica-po-prawej-(anglik)')\n",
    "\n",
    "    # param_vat-free {'Tak' (25), None (106469)} -> vat_free\n",
    "    df['vat_free'] = df['param_vat-free'].map(bool_transform)\n",
    "    feats_redundant.append('param_vat-free')\n",
    "\n",
    "    # param_acrylic {'Tak' (4), None (106490)}, param_akryl-(niemetalizowany) {'Tak' (4172), 'metallic' (4) None (102318)} -> acrylic_car_paint\n",
    "    merge_labels(df, 'param_akryl-(niemetalizowany)', 'param_acrylic', 'acrylic_car_paint', transform=lambda x: x == 'Tak' or x == 'acrylic', unknown_value=False)\n",
    "\n",
    "    # param_tuning {'Tak' (583), None (105911)} -> tuning\n",
    "    df['tuning'] = df['param_tuning'].map(bool_transform)\n",
    "    feats_redundant.append('param_tuning')\n",
    "\n",
    "    # param_matowy {'Tak' (319), None (106175)} -> mat_car_paint\n",
    "    df['mat_car_paint'] = df['param_matowy'].map(bool_transform)\n",
    "    feats_redundant.append('param_matowy')\n",
    "    \n",
    "    num_transform = lambda x: np.int64(num_filter(x))\n",
    "    \n",
    "    merge_labels(df, 'param_rok-produkcji', 'param_year', 'production_year_num', transform=num_transform, unknown_value=-1)\n",
    "    \n",
    "    merge_labels(df, 'param_moc', 'param_engine-power', 'engine_power_num', transform=num_transform, unknown_value=-1)\n",
    "    \n",
    "    merge_labels(df, 'param_napęd', 'param_transmission', 'transmission')\n",
    "    categorize_feature(df, 'transmission', 'transmission_cat', indexers=indexers)\n",
    "    \n",
    "    merge_labels(df, 'param_skrzynia-biegów', 'param_gearbox', 'gearbox')\n",
    "    categorize_feature(df, 'gearbox', 'gearbox_cat', indexers=indexers, average_func=np.mean)\n",
    "\n",
    "    merge_labels(df, 'param_typ', 'param_body-type', 'body_type', transform=lambda x: x.lower())\n",
    "    categorize_feature(df, 'body_type', 'body_type_cat', indexers=indexers)\n",
    "    \n",
    "    merge_labels(df, 'param_marka-pojazdu', 'param_make', 'vehicle_brand', unknown_value='unknown')\n",
    "    df.loc[df['vehicle_brand'] == 'Inny', 'vehicle_brand'] = 'unknown'\n",
    "    \n",
    "    merge_labels(df, 'param_model-pojazdu', 'param_model', 'vehicle_model', unknown_value='unknown')\n",
    "    \n",
    "    s_feat0 = 'vehicle_brand'\n",
    "    s_feat1 = 'vehicle_model'\n",
    "    feat = 'vehicle_brand_model'\n",
    "    feat_cat = 'vehicle_brand_model_cat'\n",
    "    df['vehicle_brand_model'] = [a + ' ' + b if a != None and a != 'unknown' and b != None and b != 'unknown' else 'unknown' for a, b in zip(df[s_feat0], df[s_feat1])]\n",
    "    if indexers != None and feat in indexers:\n",
    "        vehicle_brand_categories, vehicle_brands_very_cheap, vehicle_brands_cheap, vehicle_brands_expensive, vehicle_brands_very_expensive = indexers[feat]\n",
    "        \n",
    "        df[feat_cat] = [vehicle_brand_categories[x] if x in vehicle_brand_categories else \n",
    "                        vehicle_brand_categories['Other Very Cheap'] if x in vehicle_brands_very_cheap else \n",
    "                        vehicle_brand_categories['Other Cheap'] if x in vehicle_brands_cheap else \n",
    "                        vehicle_brand_categories['Other Expensive'] if x in vehicle_brands_expensive else\n",
    "                        vehicle_brand_categories['Other Very Expensive'] if x in vehicle_brands_very_expensive else\n",
    "                        vehicle_brand_categories['unknown'] for x in df[feat]]\n",
    "    else:\n",
    "        vehicle_brands = set(df[feat])\n",
    "        vehicle_brand_info = {}\n",
    "        vehicle_brands_prices = {}\n",
    "        vehicle_brancs_counts = {}\n",
    "        vehicle_brands_cheap = []\n",
    "        vehicle_brands_very_cheap = []\n",
    "        vehicle_brands_expensive = []\n",
    "        vehicle_brands_very_expensive = []\n",
    "        mean_price_value = np.mean(df['price_value'])\n",
    "        median_price_value = np.median(df['price_value'])\n",
    "        price_value_p0 = np.percentile(train['price_value'], 15)\n",
    "        price_value_p1 = np.percentile(train['price_value'], 50)\n",
    "        price_value_p2 = np.percentile(train['price_value'], 80)\n",
    "\n",
    "        for brand in vehicle_brands:\n",
    "            rows = df[df[feat] == brand]\n",
    "            vehicle_brand_info[brand] = (len(rows), np.mean(rows['price_value']), np.median(rows['price_value']))\n",
    "\n",
    "        for b, (l, mean, median) in vehicle_brand_info.items():\n",
    "            if l < 5 and b != 'unknown':\n",
    "                if median < price_value_p0:\n",
    "                    vehicle_brands_very_cheap.append(b)\n",
    "                    df.loc[df[feat] == b, feat] = 'Other Very Cheap'\n",
    "                elif median < price_value_p1:\n",
    "                    vehicle_brands_cheap.append(b)\n",
    "                    df.loc[df[feat] == b, feat] = 'Other Cheap'\n",
    "                elif median < price_value_p2:\n",
    "                    vehicle_brands_expensive.append(b)\n",
    "                    df.loc[df[feat] == b, feat] = 'Other Expensive'\n",
    "                else:\n",
    "                    vehicle_brands_very_expensive.append(b)\n",
    "                    df.loc[df[feat] == b, feat] = 'Other Very Expensive'\n",
    "\n",
    "        vehicle_brands = set(df[feat])\n",
    "        vehicle_brand_info = {}\n",
    "        \n",
    "        for brand in vehicle_brands:\n",
    "            rows = df[df[feat] == brand]\n",
    "            if brand != 'unknown':\n",
    "                vehicle_brand_info[brand] = (brand, len(rows), np.mean(rows['price_value']), np.median(rows['price_value']))\n",
    "            else:\n",
    "                vehicle_brand_info[brand] = (brand, len(rows), mean_price_value, median_price_value)\n",
    "\n",
    "        sorted_info = sorted(list(vehicle_brand_info.values()), key=lambda tup: tup[3])\n",
    "        vehicle_brand_categories = {}\n",
    "\n",
    "        for i, (b, l, m, s) in enumerate(sorted_info):\n",
    "            vehicle_brand_categories[b] = i\n",
    "\n",
    "        indexers[feat] = (vehicle_brand_categories, vehicle_brands_very_cheap, vehicle_brands_cheap, vehicle_brands_expensive, vehicle_brands_very_expensive)\n",
    "        \n",
    "        df[feat_cat] = [vehicle_brand_categories[x] if x in vehicle_brand_categories else -1 for x in df[feat]]\n",
    "    \n",
    "    feats_redundant.append(feat) \n",
    "    \n",
    "    \n",
    "    feat = 'vehicle_brand'\n",
    "    feat_cat = 'vehicle_brand_cat'\n",
    "    if indexers != None and feat in indexers:\n",
    "        vehicle_brand_categories, vehicle_brands_very_cheap, vehicle_brands_cheap, vehicle_brands_expensive, vehicle_brands_very_expensive = indexers[feat]\n",
    "        \n",
    "        df[feat_cat] = [vehicle_brand_categories[x] if x in vehicle_brand_categories else \n",
    "                        vehicle_brand_categories['Other Very Cheap'] if x in vehicle_brands_very_cheap else \n",
    "                        vehicle_brand_categories['Other Cheap'] if x in vehicle_brands_cheap else \n",
    "                        vehicle_brand_categories['Other Expensive'] if x in vehicle_brands_expensive else\n",
    "                        vehicle_brand_categories['Other Very Expensive'] if x in vehicle_brands_very_expensive else\n",
    "                        vehicle_brand_categories['unknown'] for x in df[feat]]\n",
    "    else:\n",
    "        vehicle_brands = set(df[feat])\n",
    "        vehicle_brand_info = {}\n",
    "        vehicle_brands_prices = {}\n",
    "        vehicle_brancs_counts = {}\n",
    "        vehicle_brands_cheap = []\n",
    "        vehicle_brands_very_cheap = []\n",
    "        vehicle_brands_expensive = []\n",
    "        vehicle_brands_very_expensive = []\n",
    "        mean_price_value = np.mean(df['price_value'])\n",
    "        median_price_value = np.median(df['price_value'])\n",
    "        price_value_p0 = np.percentile(train['price_value'], 30)\n",
    "        price_value_p1 = np.percentile(train['price_value'], 60)\n",
    "        price_value_p2 = np.percentile(train['price_value'], 90)\n",
    "\n",
    "        for brand in vehicle_brands:\n",
    "            rows = df[df[feat] == brand]\n",
    "            vehicle_brand_info[brand] = (len(rows), np.mean(rows['price_value']), np.median(rows['price_value']))\n",
    "\n",
    "        for b, (l, mean, median) in vehicle_brand_info.items():\n",
    "            if l < 500 and b != 'unknown':\n",
    "                if median < price_value_p0:\n",
    "                    vehicle_brands_very_cheap.append(b)\n",
    "                    df.loc[df[feat] == b, feat] = 'Other Very Cheap'\n",
    "                elif median < price_value_p1:\n",
    "                    vehicle_brands_cheap.append(b)\n",
    "                    df.loc[df[feat] == b, feat] = 'Other Cheap'\n",
    "                elif median < price_value_p2:\n",
    "                    vehicle_brands_expensive.append(b)\n",
    "                    df.loc[df[feat] == b, feat] = 'Other Expensive'\n",
    "                else:\n",
    "                    vehicle_brands_very_expensive.append(b)\n",
    "                    df.loc[df[feat] == b, feat] = 'Other Very Expensive'\n",
    "\n",
    "        vehicle_brands = set(df[feat])\n",
    "        vehicle_brand_info = {}\n",
    "        \n",
    "        for brand in vehicle_brands:\n",
    "            rows = df[df[feat] == brand]\n",
    "            if brand != 'unknown':\n",
    "                vehicle_brand_info[brand] = (brand, len(rows), np.mean(rows['price_value']), np.median(rows['price_value']))\n",
    "            else:\n",
    "                vehicle_brand_info[brand] = (brand, len(rows), mean_price_value, median_price_value)\n",
    "\n",
    "        sorted_info = sorted(list(vehicle_brand_info.values()), key=lambda tup: tup[3])\n",
    "        vehicle_brand_categories = {}\n",
    "        \n",
    "        for i, (b, l, m, s) in enumerate(sorted_info):\n",
    "            vehicle_brand_categories[b] = i\n",
    "\n",
    "        indexers[feat] = (vehicle_brand_categories, vehicle_brands_very_cheap, vehicle_brands_cheap, vehicle_brands_expensive, vehicle_brands_very_expensive)\n",
    "        \n",
    "        df[feat_cat] = [vehicle_brand_categories[x] if x in vehicle_brand_categories else -1 for x in df[feat]]\n",
    "    \n",
    "    feats_redundant.append(feat)\n",
    "    \n",
    "    categorize_feature(df, 'vehicle_model', 'vehicle_model_cat', indexers=indexers)\n",
    "\n",
    "    merge_labels(df, 'param_version', 'param_wersja', 'version', transform=lambda x: x.lower())\n",
    "    categorize_feature(df, 'version', 'version_cat', indexers=indexers)\n",
    "    \n",
    "    merge_labels(df, 'param_kod-silnika', 'param_engine-code', 'engine_code', transform=lambda x: x.lower())\n",
    "    categorize_feature(df, 'engine_code', 'engine_code_cat', indexers=indexers)\n",
    "\n",
    "    merge_labels(df, 'param_pojemność-skokowa', 'param_engine-capacity', 'engine_capacity', unknown_value='unknown')\n",
    "    categorize_feature(df, 'engine_capacity', 'engine_capacity_cat', indexers=indexers)\n",
    "\n",
    "    merge_labels(df, 'param_rodzaj-paliwa', 'param_fuel-type', 'param_fuel_type')\n",
    "    categorize_feature(df, 'param_fuel_type', 'param_fuel_type_cat', indexers=indexers)\n",
    "    \n",
    "    s_feat0 = 'param_kraj-pochodzenia'\n",
    "    s_feat1 = 'param_country-of-origin'\n",
    "    feat = 'country_of_origin'\n",
    "    feat_cat = 'country_of_origin_cat'\n",
    "    df[feat] = [a if a != None else b if b != None else 'unknown' for a, b in zip(df[s_feat0], df[s_feat1])]\n",
    "    \n",
    "    if indexers != None and feat in indexers:\n",
    "        countries_categories, countries_cheap, countries_expensive = indexers[feat]\n",
    "        df[feat_cat] = [countries_categories[x] if x in countries_categories else \n",
    "                        countries_categories['Other Cheap'] if x in countries_cheap else \n",
    "                        countries_categories['Other Expensive'] if x in countries_expensive else\n",
    "                        countries_categories['unknown'] for x in df[feat]]\n",
    "    else:\n",
    "        countries = set(df[feat])\n",
    "        countries_info = {}\n",
    "        countries_cheap = []\n",
    "        countries_expensive = []\n",
    "        mean_price_value = np.mean(df['price_value'])\n",
    "        median_price_value = np.median(df['price_value'])\n",
    "\n",
    "        for country in countries:\n",
    "            rows = df[df[feat] == country]\n",
    "            countries_info[country] = (len(rows), np.mean(rows['price_value']), np.median(rows['price_value']))\n",
    "\n",
    "        for c, (l, mean, median) in countries_info.items():\n",
    "            if l < 500:\n",
    "                if median < median_price_value:\n",
    "                    countries_cheap.append(c)\n",
    "                    df.loc[df[feat] == c, feat] = 'Other Cheap'\n",
    "                else:\n",
    "                    countries_expensive.append(c)\n",
    "                    df.loc[df[feat] == c, feat] = 'Other Expensive'\n",
    "\n",
    "        countries = set(df[feat])\n",
    "        countries_info = {}\n",
    "\n",
    "        for country in countries:\n",
    "            rows = df[df[feat] == country]\n",
    "            if country != 'unknown':\n",
    "                countries_info[country] = (country, len(rows), np.mean(rows['price_value']), np.median(rows['price_value']))\n",
    "            else:\n",
    "                countries_info[country] = (country, len(rows), mean_price_value, median_price_value)\n",
    "\n",
    "        sorted_info = sorted(list(countries_info.values()), key=lambda tup: tup[3])\n",
    "        countries_categories = {}\n",
    "\n",
    "        for i, (c, l, m, s) in enumerate(sorted_info):\n",
    "            countries_categories[c] = i\n",
    "\n",
    "        indexers[feat] = (countries_categories, countries_cheap, countries_expensive)\n",
    "\n",
    "        df[feat_cat] = [countries_categories[x] if x in countries_categories else -1 for x in df[feat]]\n",
    "    \n",
    "    feats_redundant.append(s_feat0)\n",
    "    feats_redundant.append(s_feat1)\n",
    "    \n",
    "    merge_labels(df, 'param_przebieg', 'param_mileage', 'mileage_num', transform=num_transform, unknown_value=-1)\n",
    "    df['mileage_num'] = [a if a > -1 else b if b > 800 else -1 for a, b in zip(df['mileage_num'], df['engine_power_num'])]\n",
    "    df['engine_power_num'] = df['engine_power_num'].map(lambda x: -1 if x > 800 else x)\n",
    "    df['mileage'] = pd.cut(df['engine_power_num'], bins=[0, 5, 50000, 100000, 150000, 200000, 250000, 300000, 350000, 1000000000], include_lowest=True, labels=['< 5k km', '5k-50k km', '50k-100k km', '100k-150k km', '150k-200k km', '200k-250k km', '250k-300k km', '300k-350k km', '> 350k km'])\n",
    "    if indexers != None and 'mileage' in indexers:\n",
    "        df['mileage_cat'] = indexers['mileage'].get_indexer(df['mileage'])\n",
    "    else:\n",
    "        df['mileage_cat'], indexer = pd.factorize(df['mileage'])\n",
    "#         indexers['mileage'] = indexer #błąd\n",
    "\n",
    "    max_mileage = 500001\n",
    "    mileage_median = np.median(df['mileage_num'])\n",
    "    df['mileage_num_reversed'] = df['mileage_num'].map(lambda x: mileage_median if x < 0 else max_mileage - x if x < max_mileage else 0)\n",
    "    feats_redundant.append('mileage')\n",
    "\n",
    "    merge_labels(df, 'param_kolor', 'param_color', 'color', transform=lambda x: x.lower())\n",
    "    categorize_feature(df, 'color', 'color_cat', indexers=indexers)\n",
    "    \n",
    "    merge_labels(df, 'param_emisja-co2', 'param_co2-emissions', 'co2_emissions', transform=lambda x: x.lower())\n",
    "    categorize_feature(df, 'co2_emissions', 'co2_emissions_cat', indexers=indexers)\n",
    "    \n",
    "    categorize_feature(df, 'seller_name', 'seller_name_cat', indexers=indexers)\n",
    "\n",
    "    # seller_type ('Osoba prywatna' [41804], 'Dealer' [106385], None [109]), param_oferta-od ('Osoby prywatnej' [41808], 'Firmy' [64577], None [109]) -> private_seller\n",
    "    df['private_seller'] = [a == 'Osoba prywatna' or b == 'Osoby prywatnej' for a, b in zip(df.seller_type, df['param_oferta-od'])]\n",
    "    df['private_seller'] = df['private_seller'].astype(np.bool)\n",
    "    df['dealer_seller'] = [a == 'Dealer' or b == 'Firmy' for a, b in zip(df.seller_type, df['param_oferta-od'])]\n",
    "    df['dealer_seller'] = df['dealer_seller'].astype(np.bool)\n",
    "    feats_redundant.extend(['seller_type', 'param_oferta-od'])\n",
    "\n",
    "    df['car_state'] = [1 if x == 'Nowe' else 0 if x == 'Używane' else -1 for x in df['param_stan']]\n",
    "    feats_redundant.append('param_stan')\n",
    "\n",
    "    merge_labels(df, 'param_liczba-miejsc', 'param_nr-of-seats', 'seats_count', transform=lambda x: np.int8(x), unknown_value=-1)\n",
    "\n",
    "    merge_labels(df, 'param_liczba-drzwi', 'param_door-count', 'doors_count', transform=lambda x: np.int8(x), unknown_value=-1)\n",
    "    \n",
    "    merge_labels(df, 'param_pierwsza-rejestracja', 'param_first-registration', 'param_first_registration_date', transform=norm_date)\n",
    "    df['param_first_registration_date'] = pd.to_datetime(df['param_first_registration_date'])\n",
    "    \n",
    "\n",
    "    df['param_first_registration_year'] = df['param_first_registration_date'].dt.year\n",
    "    df['param_first_registration_year'].fillna(-1, inplace=True)\n",
    "\n",
    "    df['param_first_registration_month'] = df['param_first_registration_date'].dt.month\n",
    "    df['param_first_registration_month'].fillna(-1, inplace=True)\n",
    "\n",
    "    merge_labels(df, 'param_miesięczna-rata', 'param_monthly-payment-value', 'monthly_payment_num', transform=lambda x: np.float(float_filter(x)), unknown_value=-1)\n",
    "\n",
    "    df['seller_city'] = df['seller_address'].map(extract_city)\n",
    "    categorize_feature(df, 'seller_city', 'seller_city_cat', indexers=indexers, del_feat=False)\n",
    "    \n",
    "    regions_str = 'dolnośląskie, kujawsko-pomorskie, lubelskie, lubuskie, łódzkie, małopolskie, mazowieckie, opolskie, podkarpackie, podlaskie, pomorskie, śląskie, świętokrzyskie, warmińsko-mazurskie, wielkopolskie, zachodniopomorskie'\n",
    "    regions = regions_str.split(', ')\n",
    "    for region in regions:\n",
    "        df['region'] = df['seller_address'].map(lambda x: region if x != None and region in x else x)\n",
    "    df['region'] = [a if a != None else city_to_voivodeship_map[b] if b != None and b in city_to_voivodeship_map else None for a, b in zip(df['region'], df['seller_city'])]\n",
    "    categorize_feature(df, 'region', 'region_cat', indexers=indexers)\n",
    "    feats_redundant.append('seller_city')\n",
    "\n",
    "    df['initial_payment_num'] = [np.int64(num_filter(a)) if a != None else -1 for a in df['param_opłata-początkowa']]\n",
    "    feats_redundant.append('param_opłata-początkowa')\n",
    "    \n",
    "    df['buyout_num'] = [np.int64(num_filter(a)) if a != None else -1 for a in df['param_wartość-wykupu']]\n",
    "    feats_redundant.append('param_wartość-wykupu')\n",
    "    \n",
    "    df['remaining_installment_num'] = [np.int64(num_filter(a)) if a != None else -1 for a in df['param_liczba-pozostałych-rat']]\n",
    "    feats_redundant.append('param_liczba-pozostałych-rat')\n",
    "\n",
    "    categorize_feature(df, 'price_currency', 'price_currency_cat', indexers=indexers)\n",
    "    \n",
    "    if 'price_value' in df:\n",
    "        df['price_value_log'] = np.log(df['price_value'])\n",
    "        \n",
    "    feats_to_delete = feats_useless + feats_redundant\n",
    "\n",
    "    cols = df.columns\n",
    "    for feat in feats_to_delete:\n",
    "        if feat in cols:\n",
    "            del df[feat]\n",
    "\n",
    "    return df, (indexers if indexers != None else indexers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Funkcje do nauki modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feats(df):\n",
    "    feats = df.select_dtypes(include=[np.int, np.float, np.bool]).columns\n",
    "    \n",
    "    return feats[ (feats != 'car_id') & (feats != 'price_value') & (feats != 'price_value_log') ].values\n",
    "\n",
    "def get_X(df):\n",
    "    return df[  get_feats(df) ].values\n",
    "\n",
    "def get_y(df, target_var='price_value'):\n",
    "    return train[target_var].values\n",
    "\n",
    "def get_models():\n",
    "    return [\n",
    "        ('dt-5md', DecisionTreeRegressor(max_depth=5)),\n",
    "        ('dt-10md', DecisionTreeRegressor(max_depth=10)),\n",
    "        ('dt-15md', DecisionTreeRegressor(max_depth=15)),\n",
    "        ('dt-20md', DecisionTreeRegressor(max_depth=20)),\n",
    "        ('random_forest-5md', RandomForestRegressor(max_depth=5)),\n",
    "        ('random_forest-10md', RandomForestRegressor(max_depth=10)),\n",
    "        ('random_forest-15md', RandomForestRegressor(max_depth=15)),\n",
    "        ('random_forest-20md', RandomForestRegressor(max_depth=20)),\n",
    "        ('xgboost-5md', XGBRegressor(max_depth=5))\n",
    "    ]\n",
    "\n",
    "def mae_log_eval(y_log_pred, dtrain):\n",
    "    y_log_true = dtrain.get_label()\n",
    "    \n",
    "    shift = 10\n",
    "    y_true = np.float64(np.exp(y_log_true)) - shift\n",
    "    y_pred = np.float64(np.exp(y_log_pred)) - shift\n",
    "\n",
    "    return 'mae', mae(y_true, y_pred)\n",
    "\n",
    "def mae_eval(y_pred, dtrain):\n",
    "    y_true = dtrain.get_label()\n",
    "    \n",
    "    shift = 10\n",
    "\n",
    "    return 'mae', mae(y_true - shift, y_pred - shift)\n",
    "\n",
    "def run_cv(model, X, y, train, folds=4, target_log=False,cv_type=KFold, success_metric=mae):\n",
    "    cv = cv_type(n_splits=folds)\n",
    "    \n",
    "    scores = []\n",
    "    for train_idx, test_idx in cv.split(X):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        test = train.copy()\n",
    "        test = test.iloc[test_idx]\n",
    "\n",
    "        if target_log:\n",
    "            y_train = np.log(y_train)\n",
    "            y_test = np.log(y_test)\n",
    "\n",
    "        eval_set = [(X_train, y_train), (X_test, y_test)]\n",
    "\n",
    "        if target_log:\n",
    "            model.fit(X_train, y_train, eval_set=eval_set, eval_metric=mae_log_eval, verbose=False)\n",
    "        else:\n",
    "            model.fit(X_train, y_train, eval_set=eval_set, eval_metric=mae_eval, verbose=False)\n",
    "        \n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        if target_log:\n",
    "            y_test = np.exp(y_test)\n",
    "            y_pred = np.exp(y_pred)\n",
    "            y_pred[y_pred < 400] = 400\n",
    "        \n",
    "        score = success_metric(y_test, y_pred)\n",
    "        scores.append( score )\n",
    "        \n",
    "    return np.mean(scores), np.std(scores)\n",
    "\n",
    "\n",
    "def plot_learning_curve(model, title, X, y, ylim=None, cv=None, train_sizes=np.linspace(.1, 1.0, 5), target_log=False):\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.title(title)\n",
    "    if ylim is not None:plt.ylim(*ylim)\n",
    "\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    \n",
    "    if target_log:\n",
    "        y = np.log(y)\n",
    "    \n",
    "    def my_scorer(model, X, y):\n",
    "        y_pred = model.predict(X)\n",
    "        \n",
    "        if target_log:\n",
    "            y = np.exp(y)\n",
    "            y_pred = np.exp(y_pred)\n",
    "            y_pred[y_pred < 400] = 400\n",
    "        \n",
    "        return mae(y, y_pred)\n",
    "\n",
    "        \n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        model, X, y, cv=cv, n_jobs=1, train_sizes=train_sizes, scoring=my_scorer) # n_jobs > 1 not working\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    \n",
    "    return plt\n",
    "\n",
    "\n",
    "def run(train, models=get_models(), plot_lc=False, folds=3, ylim=(0, 1), target_log=False):\n",
    "    X, y  = get_X(train), get_y(train)\n",
    "\n",
    "    for model_name, model in models:\n",
    "        score_mean, score_std = run_cv(model, X, y, train, folds=folds, target_log=target_log)\n",
    "        print(\"[{0}]: {1} +/-{2}\".format(model_name, score_mean, score_std))\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        if False == plot_lc: continue\n",
    "        plt = plot_learning_curve(model, model_name, X, y, cv=folds, target_log=target_log)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przygotowanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = original_train.copy()\n",
    "\n",
    "# drop duplicates\n",
    "feats = train.columns\n",
    "feats = feats[(feats != 'breadcrumb') & (feats != 'price_details') & (feats != 'car_id') & (feats != 'created_at')].values\n",
    "train = train.drop_duplicates(feats)\n",
    "\n",
    "%time prepared_train, indexers = prepare_data(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = original_test.copy()\n",
    "\n",
    "prepared_test, a = prepare_data(test, indexers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nauka modelu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model 1**\n",
    "\n",
    "Lokalny wynik: 5437.732148466895 +/-151.16660205998767\n",
    "\n",
    "Kaggle: 5524.91166 / 5614.16511"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = prepared_train.copy()\n",
    "\n",
    "def fair_obj(y_true, y_pred):\n",
    "    x = y_pred - y_true\n",
    "\n",
    "    den = abs(x) + fair_constant\n",
    "    \n",
    "    grad = fair_constant * x / den\n",
    "    hess = (fair_constant * fair_constant) / (den * den)\n",
    "    \n",
    "    return grad, hess\n",
    "\n",
    "xgb_params = {\n",
    "    'objective': fair_obj,\n",
    "    'n_jobs': 4,\n",
    "    'max_depth': 13, \n",
    "    'n_estimators': 280,\n",
    "    'learning_rate': 0.11417783260309153,\n",
    "    'random_state': 6700,\n",
    "    'colsample_bytree': 0.8303395340380215,\n",
    "    'min_child_weight': 8,\n",
    "    'reg_alpha': 1.418978766944595,\n",
    "    'reg_lambda': 0.9766322222818731,\n",
    "    'subsample': 0.9300215313325608\n",
    "}\n",
    "fair_constant = 4698\n",
    "folds = 10\n",
    "target_log = True\n",
    "\n",
    "model = ('xgboost-{0}fc-{1}f'.format(fair_constant, folds), XGBRegressor(**xgb_params))\n",
    "(model_name, xgb_rmodel) = model\n",
    "\n",
    "%time run(train, models=[model], plot_lc=False, target_log=target_log, folds=folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model 2**\n",
    "\n",
    "Lokalny wynik: 5417.678453461945 +/-114.3701416632329\n",
    "\n",
    "Kaggle: 5496.60020 / 5588.13150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = prepared_train.copy()\n",
    "\n",
    "def fair_obj(y_true, y_pred):\n",
    "    x = y_pred - y_true\n",
    "\n",
    "    den = abs(x) + fair_constant\n",
    "    \n",
    "    grad = fair_constant * x / den\n",
    "    hess = (fair_constant * fair_constant) / (den * den)\n",
    "    \n",
    "    return grad, hess\n",
    "\n",
    "xgb_params = {\n",
    "    'objective': fair_obj,\n",
    "    'n_jobs': 4,\n",
    "    'max_depth': 15, \n",
    "    'n_estimators': 300,\n",
    "    'learning_rate': 0.05462990289471652,\n",
    "    'random_state': 9700,\n",
    "    'colsample_bytree': 0.8140341130120244,\n",
    "    'min_child_weight': 1,\n",
    "    'reg_alpha': 1.0835749586415848,\n",
    "    'reg_lambda': 0.985332472621205,\n",
    "    'subsample': 0.9836466473497267\n",
    "}\n",
    "fair_constant = 4847\n",
    "folds = 9\n",
    "target_log = True\n",
    "\n",
    "model = ('xgboost-{0}fc-{1}f'.format(fair_constant, folds), XGBRegressor(**xgb_params))\n",
    "(model_name, xgb_rmodel) = model\n",
    "\n",
    "%time run(train, models=[model], plot_lc=False, target_log=target_log, folds=folds)\n",
    "\n",
    "#     %time xgbfir.saveXgbFI(xgb_rmodel.get_booster(), feature_names=get_feats(train), OutputXlsxFile='bost_fi.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przewidywanie ceny na danych testowych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = prepared_test.copy()\n",
    "X_test = get_X(test)\n",
    "y_pred = xgb_rmodel.predict(X_test)\n",
    "\n",
    "if target_log:\n",
    "    y_pred = np.exp(y_pred)\n",
    "    y_pred[y_pred < 400] = 400\n",
    "\n",
    "test['price_value'] = y_pred\n",
    "\n",
    "%time test[['car_id', 'price_value']].to_csv('./output/model_' + model_name + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sprawdzanie ważności cech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time xgbfir.saveXgbFI(xgb_rmodel.get_booster(), feature_names=get_feats(train), OutputXlsxFile='bost_fi.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.read_excel('bost_fi.xlsx', 'Interaction Depth 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_excel('bost_fi.xlsx', 'Interaction Depth 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_excel('bost_fi.xlsx', 'Interaction Depth 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Połączenie wyników z modeli\n",
    "\n",
    "Docelowo funkcja trenująca powinna wspierać łączenie modeli, a najlepsza proporcja znaleziona np. za pomocą hiperopt.\n",
    "\n",
    "0.7 model_xgboost-4698fc-10f + 0.3 model_xgboost-4847fc-9f:\n",
    "\n",
    "Kaggle: 5413.38492 / 5510.88303"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res0 = pd.read_csv('./output/model_xgboost-4698fc-10f.csv')\n",
    "res1 = pd.read_csv('./output/model_xgboost-4847fc-9f.csv')\n",
    "\n",
    "res0['price_value_0'] = res0['price_value']\n",
    "del res0['price_value']\n",
    "\n",
    "res1['price_value_1'] = res1['price_value']\n",
    "del res1['price_value']\n",
    "\n",
    "merged_res = pd.merge(res0, res1, on='car_id')\n",
    "a = 0.7\n",
    "b = 0.3\n",
    "merged_res['price_value'] = [a * p0 + b * p1 for p0, p1 in zip(merged_res['price_value_0'], merged_res['price_value_1'])]\n",
    "\n",
    "merged_res[['car_id', 'price_value']].to_csv('./output/merged_model{0}.csv'.format(a), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
